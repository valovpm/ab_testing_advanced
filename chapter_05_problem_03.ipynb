{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# PARLA\n",
    "\n",
    "## Problem\n",
    "Write a function `run_bootstrap` that:\n",
    "- constructs a confidence interval of the following types:\n",
    "    - normal confidence interval\n",
    "    - percentile confidence interval\n",
    "    - central confidence interval\n",
    "- checks for statistically significant differences using bootstrapping\n",
    "- for more info check the function's docstring below\n",
    "\n",
    "## Action\n",
    "I implemented 3 different ways of calculating confidence intervals and combined them into one function\n",
    "\n",
    "## Result\n",
    "Successfully implemented the function and it passed all tests\n",
    "\n",
    "## Learning\n",
    "- I revised relevant Python, Numpy, and Scipy functionality\n",
    "- I learned (by implementing) several different ways of calculating confidence intervals\n",
    "\n",
    "## Application\n",
    "- I can apply relevant Python, Numpy, and Scipy functionality for similar data-related problems\n",
    "- I can use the implemented function to calculate different types of confidence intervals\n"
   ],
   "id": "cd87c6f85e974c4"
  },
  {
   "cell_type": "code",
   "id": "6c7ef9d6-c812-4b3c-90fa-704827f7ce61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T20:08:30.780478Z",
     "start_time": "2025-05-22T20:08:30.777517Z"
    }
   },
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "ed3a70c773496df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T20:08:30.832367Z",
     "start_time": "2025-05-22T20:08:30.827849Z"
    }
   },
   "source": [
    "\n",
    "def generate_bootstrap_metrics(\n",
    "    data_one: np.ndarray,\n",
    "    data_two: np.ndarray,\n",
    "    bootstrap_iter: int,\n",
    "    bootstrap_agg_func: str\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Generates metric values using bootstrapping.\n",
    "\n",
    "    :param data_one: Metric values in the first group.\n",
    "    :param data_two: Metric values in the second group.\n",
    "    :param bootstrap_iter: Number of bootstrap iterations.\n",
    "    :param bootstrap_agg_func: Aggregation method for the metric.\n",
    "        Possible values: ['mean', 'quantile 95'].\n",
    "\n",
    "    :return:\n",
    "        - bootstrap_metrics: A NumPy array of test statistics computed on bootstrap samples.\n",
    "        - pe_metric: A float value of the test statistic computed on the original data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a matrix of random samples\n",
    "    # Each column is a random sample from the original data (data_one or data_two)\n",
    "    # There will be bootstrap_iter columns in total\n",
    "    bootstrap_data_one = np.random.choice(data_one, size=(len(data_one), bootstrap_iter))\n",
    "    bootstrap_data_two = np.random.choice(data_two, size=(len(data_two), bootstrap_iter))\n",
    "\n",
    "    # calculate mean value\n",
    "    if bootstrap_agg_func == 'mean':\n",
    "        bootstrap_metrics = (\n",
    "            bootstrap_data_two.mean(axis=0) -\n",
    "            bootstrap_data_one.mean(axis=0)\n",
    "        )\n",
    "        pe_metric = data_two.mean() - data_one.mean()\n",
    "        return bootstrap_metrics, pe_metric\n",
    "\n",
    "    # calculate 0.95 quantile\n",
    "    elif bootstrap_agg_func == 'quantile 95':\n",
    "        q = 0.95\n",
    "        bootstrap_metrics = (\n",
    "            np.quantile(bootstrap_data_two, q, axis=0) -\n",
    "            np.quantile(bootstrap_data_one, q, axis=0)\n",
    "        )\n",
    "        pe_metric = np.quantile(data_two, q) - np.quantile(data_one, q)\n",
    "        return bootstrap_metrics, pe_metric\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"wrong value of 'bootstrap_agg_func' parameter\")\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T20:08:30.883463Z",
     "start_time": "2025-05-22T20:08:30.878226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# testing generate_bootstrap_metrics() function\n",
    "data_one, data_two = np.array([1, 3]), np.array([5, 7])\n",
    "bootstrap_iter = 10\n",
    "bootstrap_agg_func = 'mean'\n",
    "bootstrap_metrics, pe_metric = generate_bootstrap_metrics(\n",
    "    data_one, data_two, bootstrap_iter, bootstrap_agg_func\n",
    ")\n",
    "\n",
    "# testing\n",
    "# bootstrapped metrics are going to be random, therefore I only compare length\n",
    "if (len(bootstrap_metrics) == len(np.array([6., 5., 3., 4., 5., 2., 6., 4., 4., 4.])) and\n",
    "    pe_metric == 4.0\n",
    "):\n",
    "    print(f'test_01: passed')\n",
    "else:\n",
    "    print(f'test_01: failed')\n"
   ],
   "id": "528ba2a2-9f4a-4d77-85d3-58c5e0bdd2a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_01: passed\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "902db0d2-6298-4ef8-99ab-ab341e2f29bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T20:08:30.935130Z",
     "start_time": "2025-05-22T20:08:30.928481Z"
    }
   },
   "source": [
    "\n",
    "def run_bootstrap(\n",
    "    bootstrap_metrics: np.ndarray,\n",
    "    pe_metric: float,\n",
    "    alpha: float,\n",
    "    bootstrap_ci_type: str\n",
    ") -> Tuple[List[float], float]:\n",
    "    \"\"\"\n",
    "    Constructs a confidence interval and checks for statistically significant differences using bootstrapping.\n",
    "\n",
    "    :param bootstrap_metrics: A NumPy array of test statistic values computed from bootstrap samples.\n",
    "    :param pe_metric: The test statistic value computed from the original data.\n",
    "    :param alpha: Significance level.\n",
    "    :param bootstrap_ci_type: Method for constructing the confidence interval.\n",
    "        Possible values: ['normal', 'percentile', 'pivotal'].\n",
    "\n",
    "    :return:\n",
    "        - ci: A list of two floats representing the confidence interval bounds.\n",
    "        - pvalue: A float value of 0 if a statistically significant difference is found, otherwise 1.\n",
    "            Note: Computing a true p-value for arbitrary bootstrap CI methods is non-trivial.\n",
    "            Here, we use boundary values of 0 and 1 as a simplified decision rule.\n",
    "    \"\"\"\n",
    "\n",
    "    # left and right confidence interval bounds\n",
    "    l, r = 0, 0\n",
    "\n",
    "    # calculate confidence interval using normal approximation\n",
    "    if bootstrap_ci_type == 'normal':\n",
    "        l = pe_metric - sp.stats.norm.ppf(1 - alpha / 2) * bootstrap_metrics.std()\n",
    "        r = pe_metric + sp.stats.norm.ppf(1 - alpha / 2) * bootstrap_metrics.std()\n",
    "\n",
    "    # calculate confidence interval using actual bootstrap distribution of the metric\n",
    "    elif bootstrap_ci_type == 'percentile':\n",
    "        a = np.quantile(bootstrap_metrics, [alpha / 2, 1 - alpha / 2])\n",
    "        l = a[0]\n",
    "        r = a[1]\n",
    "\n",
    "    # calculate central confidence interval\n",
    "    elif bootstrap_ci_type == 'pivotal':\n",
    "        a = np.quantile(bootstrap_metrics, [alpha / 2, 1 - alpha / 2])\n",
    "        l = 2 * pe_metric - a[1]\n",
    "        r = 2 * pe_metric - a[0]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"wrong value of 'bootstrap_ci_type' parameter\")\n",
    "\n",
    "    ci = [l, r]\n",
    "\n",
    "    # calculate p-value\n",
    "    pvalue = 0.\n",
    "    if l <= 0 <= r:\n",
    "        pvalue = 1.\n",
    "    else:\n",
    "        pvalue = 0.\n",
    "\n",
    "    return ci, pvalue\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "dfe04708-dce3-49f2-908c-5db30c1652bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T20:08:30.988932Z",
     "start_time": "2025-05-22T20:08:30.981748Z"
    }
   },
   "source": [
    "\n",
    "# testing run_bootstrap() function\n",
    "# test case 01\n",
    "bootstrap_metrics = np.arange(-90, 910)\n",
    "pe_metric = 600.\n",
    "alpha = 0.05\n",
    "bootstrap_ci_types = ['normal', 'percentile', 'pivotal']\n",
    "results = {\n",
    "    'normal': [[34., 1166.], 0.0],\n",
    "    'percentile': [[-65., 884.], 1.0],\n",
    "    'pivotal': [[316., 1265.], 0.0]\n",
    "}\n",
    "\n",
    "# calculate and compare results\n",
    "for bootstrap_ci_type in bootstrap_ci_types:\n",
    "    # calculate results\n",
    "    ci, pvalue = run_bootstrap(bootstrap_metrics, pe_metric, alpha, bootstrap_ci_type)\n",
    "    ci = np.round(ci)\n",
    "    pvalue = np.round(pvalue)\n",
    "\n",
    "    # compare results\n",
    "    if (\n",
    "        np.allclose(ci, np.round(results[bootstrap_ci_type][0])) and\n",
    "        pvalue == np.round(results[bootstrap_ci_type][1])\n",
    "    ):\n",
    "        print(f'test_{bootstrap_ci_type}: passed')\n",
    "    else:\n",
    "        print(f'test_{bootstrap_ci_type}: failed')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal: passed\n",
      "test_percentile: passed\n",
      "test_pivotal: passed\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
