{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# PARLA\n",
    "\n",
    "## Problem\n",
    "On one hand, removing outliers reduces variance, which increases the sensitivity of the test.\n",
    "On the other hand, removing outliers reduces the sample size, which decreases sensitivity.\n",
    "Compare the power of tests with different proportions of removed data:\n",
    "- Use the backend response time data from `2022-04-01T12_df_web_logs.csv` for the period from March 1 to March 8, 2022.\n",
    "- The significance level is 0.05.\n",
    "- Group sizes are 1,000 users (the sample size will be larger because each user has many data points).\n",
    "- We are testing the hypothesis of equal means using Studentâ€™s t-test.\n",
    "- **The expected effect is a 1% increase in processing time.**\n",
    "- **But instead of adding the effect to the whole experimental group, add it to 1% of experimental group.**\n",
    "- **The effect in synthetic A/B tests must be added by addition of a constant to 1% of the experimental group.**\n",
    "\n",
    "As your answer, enter the option numbers sorted by **decreasing test power**.\n",
    "For example, \"12345\" means that option 1 has the highest power, and option 5 the lowest:\n",
    "1. Remove 0.02% of outliers\n",
    "2. Remove 0.2% of outliers\n",
    "3. Remove 2% of outliers\n",
    "4. Remove 10% of outliers\n",
    "5. Remove 20% of outliers\n",
    "\n",
    "Removing 2% of outliers means removing 1% of the lowest and 1% of the highest values from the sample.\n",
    "That is, keep the values that lie between `np.quantile(values, 0.01)` and `np.quantile(values, 0.99)`.\n",
    "Quantiles should be computed separately for each group.\n",
    "\n",
    "## Action\n",
    "To calculate power for different percentage of removed outliers, I:\n",
    "- loaded, transformed, and filtered the web-logs dataset\n",
    "- for each percentage of outliers:\n",
    "    - calculated left and right percentiles\n",
    "    - filtered out outliers from the web-logs data\n",
    "    - performed synthetic AB-testing 10^3 times:\n",
    "        - sampled control and experimental groups\n",
    "        - added effect to the experimental group\n",
    "        - calculated p-value, by performing t-test\n",
    "    - found empirical probability of type-II error\n",
    "    - found empirical power\n",
    "- ordered powers in descending order\n",
    "\n",
    "## Result\n",
    "Correctly assessed empirical powers:\n",
    "- of independent t-tests\n",
    "- when the effect is added by adding a constant to 1% of the experimental group\n",
    "- for different number of removed outliers\n",
    "\n",
    "## Learning\n",
    "- I revised relevant Python, Numpy, Pandas, and Scipy functionality\n",
    "- I learned how to remove a certain percentage of outliers from both sides of a distribution by using percentiles\n",
    "- I learned that the method of adding effect to experimental group has influence on statistical power\n",
    "    - In the previous study, where effect was added by multiplying the whole experimental group by a constant, there was clear pattern, showing that the more outliers we remove, the higher the power will be\n",
    "    - In the current study, where we add a constant to 1% of the experimental group, there is no such pattern\n",
    "- Therefore, I learned that in real-world one has to perform a thorough synthetic AB-testing, to find based on historical data how effect is added and how this effect influences removal of outliers and statistical power\n",
    "\n",
    "## Application\n",
    "- I can apply relevant Python, Numpy, Pandas and Scipy functionality for similar data-related problems\n",
    "- I can apply this technique of removing outliers to a real-world data-related problems\n"
   ],
   "id": "86edc1e0fdb466f3"
  },
  {
   "cell_type": "code",
   "id": "94d5b05c-b476-4d8d-988c-d827c67e8efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T13:36:14.164556Z",
     "start_time": "2025-05-24T13:36:14.161590Z"
    }
   },
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "6e139ecb-85b0-4f9c-8d07-4c520860fafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T13:56:54.139709Z",
     "start_time": "2025-05-24T13:56:52.415798Z"
    }
   },
   "source": [
    "\n",
    "# load, transform, and filter the web-logs dataset\n",
    "df = pd.read_csv('data/2022-04-01T12_df_web_logs.csv')\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df = df[(df.date >= datetime(2022, 3, 1)) & (df.date < datetime(2022, 3, 8))]\n",
    "df = df[['user_id', 'load_time']]\n",
    "print(len(df))\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       user_id  load_time\n",
       "885082  434cf2       69.8\n",
       "885083  80fa93       86.3\n",
       "885084  434cf2       58.0\n",
       "885085  a0aaab       85.2\n",
       "885086  a22f92       92.5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>load_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>885082</th>\n",
       "      <td>434cf2</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885083</th>\n",
       "      <td>80fa93</td>\n",
       "      <td>86.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885084</th>\n",
       "      <td>434cf2</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885085</th>\n",
       "      <td>a0aaab</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885086</th>\n",
       "      <td>a22f92</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "id": "c3a672da-a264-4352-a4c9-6a1d6a61364c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T13:41:23.134672Z",
     "start_time": "2025-05-24T13:36:15.631607Z"
    }
   },
   "source": [
    "\n",
    "alpha = 0.05  # significance level, probability of type-I error\n",
    "sample_size = 1000  # size of control and experimental groups\n",
    "percentage = [0.0002, 0.002, 0.02, 0.1, 0.2]  # what percentage of outliers to remove\n",
    "pvalues_dict = {p: [] for p in percentage}  # dict of lists, containing p-values for each percentage\n",
    "powers = {}  # resulting powers for different percentage of outliers\n",
    "\n",
    "# add effect in synthetic AB-testing to a small percent of data\n",
    "percent_of_data_with_effect = 0.01  # percent of data in experimental group to add effect to\n",
    "effect = 0.01\n",
    "\n",
    "# calculate unique user-ids for sampling control and experimental groups later\n",
    "user_ids = df.user_id.unique()\n",
    "print(f'len(user_ids) = {len(user_ids)}')\n",
    "\n",
    "for i in range(10**4):\n",
    "    # SAMPLE CONTROL AND EXPERIMENTAL GROUPS ######################################################\n",
    "    # sample user-ids for control and experimental groups without repetitions\n",
    "    a_user_ids, b_user_ids = np.random.choice(user_ids, size=(2, sample_size), replace=False)\n",
    "\n",
    "    # get metric values for control and experimental groups\n",
    "    a_values = df.loc[df['user_id'].isin(a_user_ids), 'load_time'].values\n",
    "    b_values = df.loc[df['user_id'].isin(b_user_ids), 'load_time'].values\n",
    "\n",
    "    # get number of values for control and experimental groups\n",
    "    # this number can be different each time,\n",
    "    # since different users have different number of metric-values\n",
    "    a_size = len(a_values)\n",
    "    b_size = len(b_values)\n",
    "\n",
    "    # calculate mean for control and experimental groups\n",
    "    a_mean = np.mean(a_values)\n",
    "    b_mean = np.mean(b_values)\n",
    "\n",
    "    # ADD EFFECT TO THE EXPERIMENTAL GROUP ########################################################\n",
    "    # get size of indexes with effect\n",
    "    b_indexes_with_effect_size = int(b_size * percent_of_data_with_effect)\n",
    "\n",
    "    # get random indexes to add effect to\n",
    "    b_indexes_with_effect = np.random.choice(\n",
    "        np.arange(b_size),\n",
    "        size=b_indexes_with_effect_size,\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    # add effect to the indexes in the experimental group\n",
    "    # since we must add effect not to the whole experimental-group,\n",
    "    # but only to a small percent of values,\n",
    "    # we must scale the effect value,\n",
    "    # i.e. we must add much more weight to each value\n",
    "    effect_value = b_mean * effect\n",
    "    effect_scale = b_size / b_indexes_with_effect_size\n",
    "    b_values[b_indexes_with_effect] += effect_value * effect_scale\n",
    "\n",
    "    # FILTER OUTLIERS FROM CONTROL AND EXPERIMENTAL GROUPS ########################################\n",
    "    for p in percentage:\n",
    "        pvalues = []\n",
    "        # filter control group\n",
    "        half = p / 2\n",
    "        left = np.quantile(a_values, half)\n",
    "        right = np.quantile(a_values, 1 - half)\n",
    "        a_values_clean = a_values[(left < a_values) & (a_values < right)]\n",
    "\n",
    "        # filter experimental group\n",
    "        left = np.quantile(b_values, half)\n",
    "        right = np.quantile(b_values, 1 - half)\n",
    "        b_values_clean = b_values[(left < b_values) & (b_values < right)]\n",
    "\n",
    "        # calculate p-value, by performing t-test\n",
    "        pvalue = sp.stats.ttest_ind(a_values_clean, b_values_clean).pvalue\n",
    "        pvalues_dict[p].append(pvalue)\n",
    "\n",
    "# calculate power\n",
    "for p in percentage:\n",
    "    pvalues = np.array(pvalues_dict[p])\n",
    "    pvalues = pvalues > alpha  # find type-II errors (false negatives)\n",
    "    beta = pvalues.astype(int).mean()  # find empirical probability of type-II error\n",
    "    power = 1 - beta  # find empirical power\n",
    "    power = np.round(power, decimals=2)\n",
    "    powers[p] = power\n",
    "\n",
    "for i in powers.items():\n",
    "    print(i)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_ids) = 35086\n",
      "(0.0002, np.float64(0.09))\n",
      "(0.002, np.float64(0.35))\n",
      "(0.02, np.float64(0.46))\n",
      "(0.1, np.float64(0.3))\n",
      "(0.2, np.float64(0.33))\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T13:41:23.192843Z",
     "start_time": "2025-05-24T13:41:23.189429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# sort powers in descending order\n",
    "powers_sorted = sorted(powers.items(), key=lambda i: i[1], reverse=True)\n",
    "powers_sorted = dict(powers_sorted)\n",
    "for i in powers_sorted.items():\n",
    "    print(i)\n"
   ],
   "id": "9bb906ffca389367",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02, np.float64(0.46))\n",
      "(0.002, np.float64(0.35))\n",
      "(0.2, np.float64(0.33))\n",
      "(0.1, np.float64(0.3))\n",
      "(0.0002, np.float64(0.09))\n"
     ]
    }
   ],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
