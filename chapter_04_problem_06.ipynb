{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# PARLA\n",
    "\n",
    "## Problem\n",
    "- Write a function to estimate probabilities of type-I and type-II errors for different methods of adding effect\n",
    "    - Two methods for adding an effect should be implemented:\n",
    "        - 'all_const': increase all values in group B by a constant (mean * effect / 100).\n",
    "        - 'all_percent': multiply all values in group B by (1 + effect / 100).\n",
    "    - The function should return:\n",
    "        - pvalues_aa: list of p-values comparing group A to A (no effect).\n",
    "        - pvalues_ab: list of p-values comparing group A to modified group B (with effect).\n",
    "        - type_one_error: estimated Type I error probability.\n",
    "        - type_two_error: estimated Type II error probability.\n",
    "    - For more info see function's docstring below\n",
    "\n",
    "## Action\n",
    "- for each control and experimental group generator provided:\n",
    "    - calculated p-value for AA-test\n",
    "    - for 'all_const' method:\n",
    "        - added effect to experimental group by adding a constant to all values\n",
    "        - calculated p-value for AB-test\n",
    "    - for 'all_percent' method:\n",
    "        - added effect to experimental group, by multiplying all values by a constant\n",
    "        - calculated p-value for AB-test\n",
    "- calculated type-I error, by taking mean of false positive flags\n",
    "- calculated type-II error, by taking mean of false negative flags\n",
    "\n",
    "## Result\n",
    "- The function was implemented and successfully passed all tests\n",
    "\n",
    "## Learning\n",
    "- I revised relevant Python and Pandas functionality\n",
    "    - I learned how to specify a type hint for generator-function\n",
    "- I learned how to compare different methods of adding an effect in synthetic AB-testing\n",
    "- I learned how to calculate type-I and type-II errors\n",
    "\n",
    "## Application\n",
    "- I can apply relevant Python and Pandas functionality for similar data-related problems\n",
    "- I can compare how different methods of adding an effect in synthetic AB-testing behave on real-world data\n",
    "- I can assess type-I and type-II errors on real-world data\n"
   ],
   "id": "bbe90d942878ce4f"
  },
  {
   "cell_type": "code",
   "id": "be45c8cd52cb7d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:13:46.990703Z",
     "start_time": "2025-05-18T19:13:45.881445Z"
    }
   },
   "source": [
    "\n",
    "from typing import Generator, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:13:47.001126Z",
     "start_time": "2025-05-18T19:13:46.996270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def create_group_generator(\n",
    "    metrics: pd.DataFrame,\n",
    "    sample_size: int,\n",
    "    n_iter: int\n",
    "    # Returns generator-function, i.e. a function that uses 'yield' to produce values lazily\n",
    "    # YieldType: type of the value that will be returned\n",
    "    # SendType: None, meaning generator doesn't use .send() method, only .next()\n",
    "    # ReturnType: None, meaning that generator stops with StopIteration, not with a value\n",
    ") -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    Generator of random groups.\n",
    "\n",
    "    :param metrics: DataFrame containing user metrics. Must include columns ['user_id', 'metric'].\n",
    "    :param sample_size: Number of users in each group.\n",
    "    :param n_iter: Number of iterations to generate random groups.\n",
    "    :return: Generator yielding tuples of two arrays with metric values for groups A and B.\n",
    "    \"\"\"\n",
    "\n",
    "    # get all unique user_ids\n",
    "    user_ids = metrics['user_id'].unique()\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # select user_ids for control and experimental groups without repetitions\n",
    "        a_user_ids, b_user_ids = np.random.choice(user_ids, size=(2, sample_size), replace=False)\n",
    "\n",
    "        # generate control and experimental groups\n",
    "        a_metric_values = metrics.loc[metrics['user_id'].isin(a_user_ids), 'metric'].values\n",
    "        b_metric_values = metrics.loc[metrics['user_id'].isin(b_user_ids), 'metric'].values\n",
    "\n",
    "        # save function state and return groups\n",
    "        yield a_metric_values, b_metric_values\n"
   ],
   "id": "e51e92aae943b7ba",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:13:47.063999Z",
     "start_time": "2025-05-18T19:13:47.050643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# testing create_group_generator()\n",
    "metrics = pd.DataFrame({'user_id': [1, 2, 3, 4], 'metric': [5, 6, 8, 9.1] })\n",
    "sample_size = 2\n",
    "n_iter = 3\n",
    "group_generator = create_group_generator(metrics, sample_size, n_iter)\n",
    "\n",
    "# the loop will run three times (n_iter)\n",
    "for metrics_a_group, metrics_b_group in group_generator:\n",
    "    print(metrics_a_group, metrics_b_group)\n",
    "\n",
    "# generator should produce two lists (control and experimental), with two values each (sample_size), three times (n_iter)\n",
    "# output should look like this (but with different random values):\n",
    "# >>> [8.  9.1] [5. 6.]\n",
    "# >>> [5.  9.1] [6. 8.]\n",
    "# >>> [5. 6.] [8.  9.1]\n"
   ],
   "id": "4939e070-2ba1-406a-a838-4b29072ad34f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.  9.1] [5. 8.]\n",
      "[8.  9.1] [5. 6.]\n",
      "[8.  9.1] [5. 6.]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ace2fe27-723b-426b-ab28-9f221b2918d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:14:24.272061Z",
     "start_time": "2025-05-18T19:14:24.264156Z"
    }
   },
   "source": [
    "\n",
    "def estimate_errors(\n",
    "    group_generator: Generator[Tuple[np.ndarray, np.ndarray], None, None],\n",
    "    effect_add_type: str,\n",
    "    effect: float,\n",
    "    alpha: float\n",
    ") -> Tuple[List[float], List[float], float, float]:\n",
    "    \"\"\"\n",
    "    Estimate Type I and Type II error probabilities.\n",
    "\n",
    "    :param group_generator: Generator that yields tuples of metric values for two groups.\n",
    "    :param effect_add_type: How to apply the effect to group B:\n",
    "        - 'all_const': increase all values in group B by a constant (mean * effect / 100).\n",
    "        - 'all_percent': multiply all values in group B by (1 + effect / 100).\n",
    "    :param effect: Effect size in percent.\n",
    "        For example, effect=3 means a 3% expected increase in the mean.\n",
    "    :param alpha: Significance level (e.g., 0.05).\n",
    "    :return:\n",
    "        - pvalues_aa: list of p-values comparing group A to A (no effect).\n",
    "        - pvalues_ab: list of p-values comparing group A to modified group B (with effect).\n",
    "        - type_one_error: estimated Type I error probability.\n",
    "        - type_two_error: estimated Type II error probability.\n",
    "    \"\"\"\n",
    "\n",
    "    pvalues_aa = []\n",
    "    pvalues_ab = []\n",
    "\n",
    "    # for each control and experimental group generator provided\n",
    "    for metrics_a_group, metrics_b_group in group_generator:\n",
    "\n",
    "        # calculated p-value for AA-test\n",
    "        pvalue_aa = np.round(\n",
    "            stats.ttest_ind(metrics_a_group, metrics_b_group).pvalue,\n",
    "            decimals=3\n",
    "        )\n",
    "\n",
    "        # added effect to experimental group by adding a constant to all values\n",
    "        # calculated p-value for AB-test\n",
    "        if effect_add_type == 'all_const':\n",
    "            pvalue_ab = np.round(\n",
    "                stats.ttest_ind(metrics_a_group, metrics_b_group + metrics_b_group.mean() * effect / 100).pvalue,\n",
    "                decimals=3\n",
    "            )\n",
    "        # added effect to experimental group, by multiplying all values by a constant\n",
    "        # calculated p-value for AB-test\n",
    "        elif effect_add_type == 'all_percent':\n",
    "            pvalue_ab = np.round(\n",
    "                stats.ttest_ind(metrics_a_group, metrics_b_group * (1 + effect / 100)).pvalue,\n",
    "                decimals=3\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"parameter 'effect_add_type' can only be 'all_const' or 'all_percent'.\")\n",
    "\n",
    "        # Add p-values\n",
    "        pvalues_aa.append(pvalue_aa)\n",
    "        pvalues_ab.append(pvalue_ab)\n",
    "\n",
    "    # calculate type-I error, by taking mean of false positive flags\n",
    "    type_one_error = (np.array(pvalues_aa) < alpha).astype(int).mean()\n",
    "\n",
    "    # calculate type-II error, by taking mean of false negative flags\n",
    "    type_two_error = (np.array(pvalues_ab) > alpha).astype(int).mean()\n",
    "\n",
    "    return pvalues_aa, pvalues_ab, type_one_error, type_two_error\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T19:24:55.340810Z",
     "start_time": "2025-05-18T19:24:55.262659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# testing function estimate_errors()\n",
    "sample_size = 100\n",
    "n_iter = 10\n",
    "effect = 6\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "# test case 01 #########################################################################\n",
    "# test 'add constant' method\n",
    "effect_add_type = 'all_const'\n",
    "\n",
    "# deterministic generator for testing purposes only\n",
    "group_generator = (\n",
    "    (np.arange(sample_size, dtype=float), np.arange(sample_size, dtype=float) + x,)\n",
    "    for x in range(n_iter)\n",
    ")\n",
    "\n",
    "# get values\n",
    "pvalues_aa, pvalues_ab, type_one_error, type_two_error = estimate_errors(\n",
    "    group_generator, effect_add_type, effect, alpha\n",
    ")\n",
    "\n",
    "# test values\n",
    "if (pvalues_aa == [1.0, 0.808, 0.626, 0.466, 0.331, 0.224, 0.145, 0.09, 0.053, 0.029] and\n",
    "    pvalues_ab == [0.47, 0.327, 0.216, 0.135, 0.08, 0.045, 0.024, 0.012, 0.006, 0.003] and\n",
    "    type_one_error == 0.1 and\n",
    "    type_two_error == 0.5):\n",
    "    print('test_01: passed')\n",
    "else:\n",
    "    print('test_01: failed')\n",
    "\n",
    "\n",
    "# test case 02 #########################################################################\n",
    "# test 'multiply by effect' method\n",
    "effect_add_type = 'all_percent'\n",
    "\n",
    "# deterministic generator for testing purposes only\n",
    "group_generator = (\n",
    "    (np.arange(sample_size, dtype=float), np.arange(sample_size, dtype=float) + x,)\n",
    "    for x in range(n_iter)\n",
    ")\n",
    "\n",
    "# get values\n",
    "pvalues_aa, pvalues_ab, type_one_error, type_two_error = estimate_errors(\n",
    "    group_generator, effect_add_type, effect, alpha\n",
    ")\n",
    "\n",
    "# test values\n",
    "if (pvalues_aa == [1.0, 0.808, 0.626, 0.466, 0.331, 0.224, 0.145, 0.09, 0.053, 0.029] and\n",
    "        pvalues_ab == [0.483, 0.342, 0.23, 0.147, 0.09, 0.052, 0.028, 0.015, 0.007, 0.003] and\n",
    "        type_one_error == 0.1 and\n",
    "        type_two_error == 0.6):\n",
    "    print('test_02: passed')\n",
    "else:\n",
    "    print('test_02: failed')\n"
   ],
   "id": "d0214da4-c293-4310-bebd-62602467fe41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_01: passed\n",
      "test_02: passed\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
